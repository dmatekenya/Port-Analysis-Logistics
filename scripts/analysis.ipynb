{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Useufl Libraries\n",
    "from IPython.display import display\n",
    "from tabulate import tabulate\n",
    "import pandas as pd\n",
    "# We'll also import seaborn, a Python graphing library\n",
    "import warnings # current version of seaborn generates a bunch of warnings that we'll ignore\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "sns.set(style=\"white\", color_codes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Some Basic Data Processing First**\n",
    "===================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Working folder\n",
    "data_dir = \"../data/\"\n",
    "output_dir = '../outputs/'\n",
    "d_file_v0 = data_dir + \"data_v0.csv\"\n",
    "\n",
    "dates = [\"T! Ship arrival\",\n",
    "         \"T2 Manifest received\",\n",
    "         \"T3 Declaration lodged\",\n",
    "         \"T4 Declaration validated\",\n",
    "         \"T5 Physical inspection\",\n",
    "         \"T6 Clearance\",\n",
    "         \"T7 Exit\"\n",
    "        ]\n",
    "d = pd.read_csv(d_file_v0, parse_dates=dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Rename columns\n",
    "old_names = d.columns\n",
    "new_names= ['declaration_yr','declaration_num','manifest_yr',\n",
    "            'manifest_num','ref_ship_service','t1_arrival',\n",
    "            't2_manifest_recvd','t3_declaration_lodged',\n",
    "            't4_declaration_validated','t5_inspection',\n",
    "            't6_clearance','t7_removal']\n",
    "d.rename(columns=dict(zip(old_names, new_names)), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Drop cases where the sequence isnt T7>T6>T5>T4>T3>T2>T1\n",
    "#So basically, if one of the time stamps is missing\n",
    "len_all = d.shape[0]\n",
    "d.dropna(axis=0,\n",
    "         how='any',\n",
    "         subset=['t1_arrival',\n",
    "            't2_manifest_recvd','t3_declaration_lodged',\n",
    "            't4_declaration_validated','t5_inspection',\n",
    "            't6_clearance','t7_removal'],inplace=True)\n",
    "\n",
    "print (\"%s rows dropped\"%(len_all-len(d)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Any duplicates on d['declaration_num']\n",
    "dup_decl = d['declaration_num'].duplicated()\n",
    "print (\"%s duplicates based on number declaration\"%(len (dup_decl[dup_decl==True])))\n",
    "\n",
    "dup_mani = d['manifest_num'].duplicated()\n",
    "print (\"%s duplicates based on number manifest\"%(len (dup_mani[dup_mani==True])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#len (dup[dup==False])\n",
    "len(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Add variables to represent the three different phases**\n",
    "=========================================================\n",
    "1. t1-start of this phase: 't1_arrival'\n",
    "2. t2-start of this phase:  't3_declaration_lodged'\n",
    "3. t3-start of this phase: 't7_removal'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Add the phases\n",
    "d['t1'] = d.t1_arrival\n",
    "d['t2'] = d.t3_declaration_lodged\n",
    "d['t3'] = d.t7_removal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Add date related variables for all time-stamps**\n",
    "===================================================\n",
    "1. date\n",
    "2. month\n",
    "3. day\n",
    "4. day of the week\n",
    "5. hr\n",
    "6. week dayr or weekend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Creates a binary variable to see whether this data is a weekday(or holiday) or week/working day\n",
    "#Hoilday list generated from: http://www.timebie.com/calendar/algeria2016.php\n",
    "holidays = ['2015-12-24','2015-11-01','2015-10-13','2015-09-25',\n",
    "           '2015-09-24','2015-06-19','2016-12-12','2016-11-01',\n",
    "           '2016-10-12','2016-09-14','2016-07-07','2016-07-05',\n",
    "           '2016-06-19','2016-05-01','2016-01-01']\n",
    "\n",
    "def week_end(row,column):\n",
    "    if row[column +\"_\" + 'wkday_name']=='Friday' or row[column +\"_\" + 'wkday_name']=='Saturday':\n",
    "        return 1\n",
    "    elif row[column +\"_\"+'date'] in holidays:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#For all the time-stamp variables add the date related variables\n",
    "def add_dates_vars (column, df):\n",
    "    d[column +\"_\" + 'yr'] = d.apply(lambda row: row[column].year,axis=1)\n",
    "    d[column +\"_\" + 'date'] = d.apply(lambda row: row[column].date().strftime('%Y-%m-%d'),axis=1)\n",
    "    d[column +\"_\" + 'month'] = d.apply(lambda row: row[column].month,axis=1)\n",
    "    d[column +\"_\" + 'day'] = d.apply(lambda row: row[column].day,axis=1)\n",
    "    d[column +\"_\" + 'wkday'] = d.apply(lambda row: row[column].weekday(),axis=1)\n",
    "    d[column +\"_\" + 'wkday_name'] = d.apply(lambda row: row[column].weekday_name,axis=1)\n",
    "    d[column +\"_\" + 'hr'] = d.apply(lambda row: row[column].hour,axis=1)\n",
    "    d[column +\"_\" + 'wkend']= d.apply(lambda row: week_end(row, column), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Now add all the date variables\n",
    "dates = ['t1_arrival','t2_manifest_recvd','t3_declaration_lodged',\n",
    "            't4_declaration_validated','t5_inspection',\n",
    "            't6_clearance','t7_removal', 't1', 't2','t3']\n",
    "for col in dates:\n",
    "    #add_dates_vars(col,d)\n",
    "    add_dates_vars (col, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Add duration variables-use exact time stamps to compute these and save as total seconds\n",
    "#Main phases\n",
    "d['t3_t1'] = d.apply(lambda row: (row['t3_declaration_lodged']-row['t1_arrival']).total_seconds(),axis=1)\n",
    "d['t6_t3'] = d.apply(lambda row: (row['t6_clearance']-row['t3_declaration_lodged']).total_seconds(),axis=1)\n",
    "d['t7_t6'] = d.apply(lambda row: (row['t7_removal']-row['t6_clearance']).total_seconds(),axis=1)\n",
    "\n",
    "#Add othger time steps\n",
    "d['t6_t5'] = d.apply(lambda row: (row['t6_clearance']-row['t5_inspection']).total_seconds(),axis=1)\n",
    "d['t5_t4'] = d.apply(lambda row: (row['t5_inspection']-row['t4_declaration_validated']).total_seconds(),axis=1)\n",
    "d['t4_t3'] = d.apply(lambda row: (row['t4_declaration_validated']-row['t3_declaration_lodged']).total_seconds(),axis=1)\n",
    "d['t3_t2'] = d.apply(lambda row: (row['t3_declaration_lodged']-row['t2_manifest_recvd']).total_seconds(),axis=1)\n",
    "d['t2_t1'] = d.apply(lambda row: (row['t3_declaration_lodged']-row['t2_manifest_recvd']).total_seconds(),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Only considering the sequences-Add step with maximum and minimum duration\n",
    "durations = ['t7_t6','t6_t5','t5_t4','t4_t3','t3_t2','t2_t1' ]\n",
    "d['max_step_duration'] = d[durations].idxmax(axis=1)\n",
    "d['min_step_duration'] = d[durations].idxmin(axis=1)\n",
    "\n",
    "#Also find out which phases takes the longest time-this could be obvious due to the number of steps at phase\n",
    "d['max_phases'] = d[['t7_t6',\"t3_t1\",'t6_t3']].idxmax(axis=1)\n",
    "d['min_phases'] = d[['t7_t6',\"t3_t1\",'t6_t3']].idxmin(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We can quickly check how the distribution is for maximum duration**\n",
    "\n",
    "The results show that step T3-T2 is the one which takes the longest time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Plot to show which step takes the longest time\n",
    "d.max_step_duration.value_counts().plot(kind='bar', \n",
    "                                        title =\"Steps with maximum duration\", \n",
    "                                        figsize=(15, 10), legend=True, fontsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Which phase takes the longest time?**\n",
    "===========================================\n",
    "Surprisingly (may be it not) the upstream phase seem to take the longest time (as shown in plot below)\n",
    "although it has few steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Plot to show which phase takes the longest time\n",
    "d.max_phases.value_counts().plot(kind='bar', \n",
    "                                        title =\"Phase with maximum duration\", \n",
    "                                        figsize=(15, 10), legend=True, fontsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compute  basic statistics for the sample**\n",
    "============================================\n",
    "In all this, the assumption is that the data is independent and identuically distributed. \n",
    "Essentially, arrival of one container doesnt affect the other BUT this could be wrong. For\n",
    "instance, if containers arrive in a batch, they may choose to process them togather.\n",
    "\n",
    "1. Container arrivals-just see count of containers by date, day of the week\n",
    "2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_date = pd.DataFrame(d.t1_arrival_date.value_counts())\n",
    "df_date.index = pd.DatetimeIndex(df_date.index)\n",
    "df_date.plot(figsize=(12,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Arrival time by month\n",
    "d.t1_arrival_month.value_counts().plot(kind='bar', \n",
    "                                        title =\"Arrival month\", \n",
    "                                        figsize=(15, 10), legend=True, fontsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Distribution of Day of the week and time (essentially hour) of the day or each time stamp**\n",
    "================================================================================================\n",
    "1. Table showing proportions across each day/hour\n",
    "2. Barplot\n",
    "3. Inferring distributions-although this isnt easy for categorical variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In the next cells I output tables for day and hourly distribution......** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Function to combine time-stamp columns into a single table for easy comparison\n",
    "def create_table(cat,df_data):\n",
    "    i=0\n",
    "    for dt in dates:\n",
    "        if i==0:\n",
    "            df = pd.DataFrame(df_data[dt + \"_\" + cat].value_counts()).reindex(['Sunday','Monday','Tuesday','Wednesday','Thursday','Friday','Saturday']) \n",
    "        else:\n",
    "            df = pd.concat([df, pd.DataFrame(df_data[dt + \"_\" + cat].value_counts()).reindex(['Sunday','Monday','Tuesday','Wednesday','Thursday','Friday','Saturday'])],axis=1, join='inner')\n",
    "        i += 1\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Compute and save the Frequencies\n",
    "output_dir = '../outputs/'\n",
    "days = create_table('wkday_name', d)\n",
    "days.to_csv(output_dir + 'wkday_freqs.csv', index=True,header=True)\n",
    "hrs = create_table('hr', d)\n",
    "hrs.to_csv(output_dir + 'hr_freqs.csv', index=True,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t1_arrival_wkday_name</th>\n",
       "      <th>t2_manifest_recvd_wkday_name</th>\n",
       "      <th>t3_declaration_lodged_wkday_name</th>\n",
       "      <th>t4_declaration_validated_wkday_name</th>\n",
       "      <th>t5_inspection_wkday_name</th>\n",
       "      <th>t6_clearance_wkday_name</th>\n",
       "      <th>t7_removal_wkday_name</th>\n",
       "      <th>t1_wkday_name</th>\n",
       "      <th>t2_wkday_name</th>\n",
       "      <th>t3_wkday_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Sunday</th>\n",
       "      <td>3123</td>\n",
       "      <td>3243</td>\n",
       "      <td>3423</td>\n",
       "      <td>3417.0</td>\n",
       "      <td>3412.0</td>\n",
       "      <td>3174</td>\n",
       "      <td>2912</td>\n",
       "      <td>3123</td>\n",
       "      <td>3423</td>\n",
       "      <td>2912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Monday</th>\n",
       "      <td>3070</td>\n",
       "      <td>2696</td>\n",
       "      <td>3748</td>\n",
       "      <td>3377.0</td>\n",
       "      <td>3382.0</td>\n",
       "      <td>3392</td>\n",
       "      <td>3185</td>\n",
       "      <td>3070</td>\n",
       "      <td>3748</td>\n",
       "      <td>3185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tuesday</th>\n",
       "      <td>2803</td>\n",
       "      <td>3007</td>\n",
       "      <td>3656</td>\n",
       "      <td>3438.0</td>\n",
       "      <td>3436.0</td>\n",
       "      <td>3527</td>\n",
       "      <td>3413</td>\n",
       "      <td>2803</td>\n",
       "      <td>3656</td>\n",
       "      <td>3413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wednesday</th>\n",
       "      <td>3617</td>\n",
       "      <td>2974</td>\n",
       "      <td>3423</td>\n",
       "      <td>3782.0</td>\n",
       "      <td>3784.0</td>\n",
       "      <td>3724</td>\n",
       "      <td>3649</td>\n",
       "      <td>3617</td>\n",
       "      <td>3423</td>\n",
       "      <td>3649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Thursday</th>\n",
       "      <td>3497</td>\n",
       "      <td>4721</td>\n",
       "      <td>3646</td>\n",
       "      <td>3895.0</td>\n",
       "      <td>3895.0</td>\n",
       "      <td>4089</td>\n",
       "      <td>3978</td>\n",
       "      <td>3497</td>\n",
       "      <td>3646</td>\n",
       "      <td>3978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Friday</th>\n",
       "      <td>1081</td>\n",
       "      <td>138</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>64</td>\n",
       "      <td>1081</td>\n",
       "      <td>5</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Saturday</th>\n",
       "      <td>727</td>\n",
       "      <td>1139</td>\n",
       "      <td>17</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7</td>\n",
       "      <td>717</td>\n",
       "      <td>727</td>\n",
       "      <td>17</td>\n",
       "      <td>717</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           t1_arrival_wkday_name  t2_manifest_recvd_wkday_name  \\\n",
       "Sunday                      3123                          3243   \n",
       "Monday                      3070                          2696   \n",
       "Tuesday                     2803                          3007   \n",
       "Wednesday                   3617                          2974   \n",
       "Thursday                    3497                          4721   \n",
       "Friday                      1081                           138   \n",
       "Saturday                     727                          1139   \n",
       "\n",
       "           t3_declaration_lodged_wkday_name  \\\n",
       "Sunday                                 3423   \n",
       "Monday                                 3748   \n",
       "Tuesday                                3656   \n",
       "Wednesday                              3423   \n",
       "Thursday                               3646   \n",
       "Friday                                    5   \n",
       "Saturday                                 17   \n",
       "\n",
       "           t4_declaration_validated_wkday_name  t5_inspection_wkday_name  \\\n",
       "Sunday                                  3417.0                    3412.0   \n",
       "Monday                                  3377.0                    3382.0   \n",
       "Tuesday                                 3438.0                    3436.0   \n",
       "Wednesday                               3782.0                    3784.0   \n",
       "Thursday                                3895.0                    3895.0   \n",
       "Friday                                     NaN                       NaN   \n",
       "Saturday                                   9.0                       9.0   \n",
       "\n",
       "           t6_clearance_wkday_name  t7_removal_wkday_name  t1_wkday_name  \\\n",
       "Sunday                        3174                   2912           3123   \n",
       "Monday                        3392                   3185           3070   \n",
       "Tuesday                       3527                   3413           2803   \n",
       "Wednesday                     3724                   3649           3617   \n",
       "Thursday                      4089                   3978           3497   \n",
       "Friday                           5                     64           1081   \n",
       "Saturday                         7                    717            727   \n",
       "\n",
       "           t2_wkday_name  t3_wkday_name  \n",
       "Sunday              3423           2912  \n",
       "Monday              3748           3185  \n",
       "Tuesday             3656           3413  \n",
       "Wednesday           3423           3649  \n",
       "Thursday            3646           3978  \n",
       "Friday                 5             64  \n",
       "Saturday              17            717  "
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
